% Created 2025-08-25 Mon 15:59
% Intended LaTeX compiler: pdflatex
\documentclass{beamer}\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{array}
\usepackage[T1]{fontenc}
\usepackage{natbib}
\lstset{
keywordstyle=\color{blue},
commentstyle=\color{red},stringstyle=\color[rgb]{0,.5,0},
basicstyle=\ttfamily\small,
columns=fullflexible,
breaklines=true,
breakatwhitespace=false,
numbers=left,
numberstyle=\ttfamily\tiny\color{gray},
stepnumber=1,
numbersep=10pt,
backgroundcolor=\color{white},
tabsize=4,
literate={~}{$\sim$}{1}{ø}{{\o}}1{æ}{{\ae}}1{å}{{\aa}}1{Ø}{{\OE}}1{Æ}{{\AE}}1{Å}{{\AA}}1,keepspaces=true,
showspaces=false,
showstringspaces=false,
xleftmargin=.23in,
frame=single,
basewidth={0.5em,0.4em},
}
\institute{}
\subtitle{With Ties To Machine Learning}
\RequirePackage[absolute, overlay]{textpos}
\setbeamertemplate{footline}[frame number]
\setbeamertemplate{navigation symbols}{}
\RequirePackage{fancyvrb}
\RequirePackage{array}
\RequirePackage{multirow}
\RequirePackage{tcolorbox}
\definecolor{mygray}{rgb}{.95, 0.95, 0.95}
\newcommand{\mybox}[1]{\vspace{.5em}\begin{tcolorbox}[boxrule=0pt,colback=mygray] #1 \end{tcolorbox}}
\newcommand{\sfootnote}[1]{\renewcommand{\thefootnote}{\fnsymbol{footnote}}\footnote{#1}\setcounter{footnote}{0}\renewcommand{\thefootnote}{\arabic{foot note}}}
\usepackage{alphalph}
\alphalph{\value{footnote}}
\setbeamertemplate{itemize item}{\textbullet}
\setbeamertemplate{itemize subitem}{-}
\setbeamertemplate{itemize subsubitem}{}
\setbeamertemplate{enumerate item}{\insertenumlabel.}
\setbeamertemplate{enumerate subitem}{\insertenumlabel.\insertsubenumlabel}
\setbeamertemplate{enumerate subsubitem}{\insertenumlabel.\insertsubenumlabel.\insertsubsubenumlabel}
\setbeamertemplate{enumerate mini template}{\insertenumlabel}
\makeatletter\def\blfootnote{\xdef\@thefnmark{}\@footnotetext}\makeatother
\newcommand{\E}{\ensuremath{\mathrm{E}}}
\renewcommand{\P}{\ensuremath{\mathrm{P}}}
\renewcommand{\d}{\ensuremath{\mathrm{d}}}
\setbeamertemplate{caption}{\raggedright\insertcaption\par}

\renewcommand*\familydefault{\sfdefault}
\itemsep2pt
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usetheme{default}
\author{\vspace{3em}\newline In memory of my very good friend Michael W Kattan}
\date{}
\title{Medical Risk Prediction Models}
\begin{document}

\maketitle
\section{Intro}
\label{sec:org45d25c5}

\begin{frame}[label={sec:orgc97b14e}]{Outline \footnote{Medical risk prediction models: with ties to machine learning. Chapman and Hall/CRC, 2021.}}
\begin{itemize}
\item Why should I care about statistical prediction models?
\item I am going to make a prediction model. What do I need to know?
\item How should I prepare for modeling?
\item I am ready to build a prediction model
\item Does my model predict accurately?
\item How do I decide between rival models?
\item What would make me an expert?
\item Can't the computer just take care of all of this?
\end{itemize}
\end{frame}
\begin{frame}[label={sec:org48a73c1}]{Right on}
\emph{The only useful function of a statistician is to make predictions, and thus to provide a basis for action} -- W. Edwards
Deming \vfill

There are many ways to make a model, and every modeling expert has
preferences regarding the general approach and tuning.
\vfill
\end{frame}
\begin{frame}[label={sec:orge53b543}]{}
\begin{center}
\includegraphics[width=.9\linewidth]{/home/tag/metropolis/Teaching/causal-prediction-workshop/lecturenotes/figure-2-predictionmodeltimeline.pdf}
\end{center}
\end{frame}
\begin{frame}[label={sec:org3255b92}]{}
\begin{center}
\includegraphics[width=.9\linewidth]{/home/tag/metropolis/Teaching/causal-prediction-workshop/lecturenotes/figure-2-blackbox-strategy.pdf}
\end{center}
\end{frame}
\begin{frame}[label={sec:org970b1b7}]{}
\begin{center}
\includegraphics[width=.9\linewidth]{/home/tag/metropolis/Teaching/causal-prediction-workshop/lecturenotes/figure-2-blackbox-model.pdf}
\end{center}
\end{frame}
\begin{frame}[label={sec:orga9ca393}]{Notation}
\begin{description}
\item[{Outcome}] $$Y(t)= \begin{cases}
      0 & \text{event-free or competing risk}\\
      1 & \text{event of interest before time t}
    \end{cases}$$
\item[{Predictors}] \qquad\(X = (X^{1},\dots,X^{p})\)
\item[{Dataset}] \qquad \(D_n=(Y_1(t),X_1, Y_2(t),X_2, \dots, Y_n(t),X_n)\)
\end{description}

\begin{align*}
\text{Building the model}&\qquad\qquad\ensuremath{r}: \ensuremath{D}_n\mapsto \ensuremath{r}(\ensuremath{D}_n)=\hat M_n\\[2em]
\text{Using the model}&\qquad\qquad \hat M_n : X_{new}\mapsto \hat M_n(X_{new})\in [0,1]\\[2em]
\text{Example: logistic regression} & \qquad\qquad \hat M_n(X) = \operatorname{expit}(\hat\alpha_n + \hat\beta_n X)
\end{align*}
\end{frame}
\begin{frame}[label={sec:orge8607f2}]{Measuring prediction performance}
\begin{block}{Calibration:}
\begin{equation*}
p\mapsto P\{Y_i(t)=1| \hat M_n(X_i)=p\}
\end{equation*}
\end{block}
\begin{block}{Discrimination:}
\begin{equation*}
  \operatorname{AUC}(t) = \operatorname{P}(\hat M_n(X_i)\ge \hat M_n(X_j)|Y_i(t)=1,Y_j(t)=0)
\end{equation*}
\end{block}
\begin{block}{Overall accuracy:}
\begin{equation*}
  \operatorname{Brier\ score}(t) = \operatorname{E}\left\{Y_i(t)-\hat M_n(X_i)\right\}^2
\end{equation*}
\end{block}
\end{frame}
\begin{frame}[label={sec:org1bfa652}]{}
Interpretation of a prediction performance measure should always
involve a benchmark, ideally that set by a rival prediction model.
\vfill

\begin{center}
\includegraphics[width=0.7\textwidth]{/home/tag/metropolis/Teaching/causal-prediction-workshop/lecturenotes/fig-5-auroc-thresholds.png}
\label{fig:1}
\end{center}

In a homogeneous population, even the perfect model can have low
discrimination ability (AUC/AUCROC). In a heterogeneous population, even a
bad model can have a high AUC.
\end{frame}
\begin{frame}[label={sec:orge1893b0}]{Rare biomarkers \ldots{}}
\begin{center}
\includegraphics[width=1.0\textwidth]{/home/tag/metropolis/Teaching/causal-prediction-workshop/lecturenotes/fig-2-newmarker.pdf}
\end{center}

\ldots{} do not show change overall predictive performance 
\end{frame}
\begin{frame}[label={sec:org3d0861c}]{}
Benchmark values for the AUC (concordance index) and Brier score at any fixed prediction time horizon t.

\begin{center}
\begin{tabular}{llll}
Benchmark prediction & AUC & Brier score & Interpretation\\
\hline
50\% always & 50\% & 25\% & useless or harmful\\
Overall event probability always & 50\% & see Figure & useless\\
Coin toss & 50\% & 50\% & harmful\\
Uniform [0,1] & 50\% & 33\% & harmful\\
\end{tabular}
\end{center}

Being a rank statistic, the AUC is blind to
miscalibration of the predicted risks.
Hence, it cannot stand alone to assess models with respect to predictive accuracy.
\end{frame}
\begin{frame}[label={sec:org4a18f1b}]{Benchmark: the null model ignores the predictor variables}
\begin{center}
\includegraphics[width=0.7\textwidth]{figure-5-theoretical-brier-score.pdf}
\end{center}

A good model outperforms the null model.
\end{frame}
\begin{frame}[label={sec:org5611efe},fragile,shrink=25]{Example}
 \begin{lstlisting}[language=r,numbers=none,otherkeywords={}, deletekeywords={}]
library(riskRegression)
train <- readRDS("./practicals/data/type1-diabetes-train.rds")
test <- readRDS("./practicals/data/type1-diabetes-test.rds")
head(train)
\end{lstlisting}
\pause
\phantomsection
\label{}
\begin{verbatim}
             pid      age sex_male diabetes_duration smoking motion   steno_prs HBA1C_pre_trt urine_albumin_pre_trt LDL_pre_trt SBP_pre_trt
1 train-28abed0e 52.92496        0          40.74757       0      0 -0.13899942      39.53003             59.187676   4.1392304    115.9685
2 train-f07f8cea 42.70053        0          36.11731       0      1  0.40351668      68.36319             42.915588   2.9280214    110.5099
3 train-f343cabb 47.57017        0          29.81477       0      0  0.54502533      52.47459             73.934960   3.7859522    110.9832
4 train-beb0e521 50.20713        0          40.73831       0      0  0.23982291      58.68347             46.645150   3.2022863    114.1410
5 train-05d45f09 40.76193        0          22.58828       0      1 -0.55949839      39.83002              7.486091   1.2928645    112.3791
6 train-82772fab 45.96690        0          28.94583       0      1  0.04637945      66.12423             96.794598   0.9119395    109.5785
  eGFR_pre_trt statin HBA1C_post_trt urine_albumin_post_trt LDL_post_trt SBP_post_trt eGFR_post_trt cvd_5year
1    104.03674      0       49.51156              95.958599     8.816790    116.41349     124.43999         0
2     90.13102      0       35.53323              44.175849     6.772076     97.39556     100.62088         0
3    102.67096      0       75.10901              96.535995     6.853455    135.02247      69.04463         0
4    113.77416      0       72.04421              39.454438     4.687593    130.34618      78.67379         0
5    104.25661      0       28.79908               5.671578     1.392458    105.75112     165.02973         0
6     98.40765      0       68.75695             230.856313     1.389660    124.03086      69.00498         0
\end{verbatim}
\end{frame}
\begin{frame}[label={sec:orgfd9b974},fragile]{Conventional model and experimental model}
 \begin{lstlisting}[language=r,numbers=none,otherkeywords={}, deletekeywords={model}]
# Logistic regression similar to Steno 1 risk engine formula
conventional_model <- glm(cvd_5year~sex_male + age + diabetes_duration + smoking + motion + HBA1C_post_trt + urine_albumin_post_trt + LDL_post_trt + SBP_post_trt + eGFR_post_trt,
             data = train, family = "binomial")
# Logistic regression with interactions and reduced number of variables
experimental_model <- glm(cvd_5year~sex_male *SBP_post_trt + age + I(age>40) * eGFR_post_trt + diabetes_duration + smoking + motion,
             data = train, family = "binomial")
\end{lstlisting}
\end{frame}
\begin{frame}[label={sec:orgd092c99},fragile]{Predicted risks for a single subject}
 \begin{lstlisting}[language=r,numbers=none,otherkeywords={}, deletekeywords={model}]
data.frame("subject id" = c(24,24),
           "model" = c("conventional","experimental"),
           "risk prediction" = c(predictRisk(conventional_model,newdata = test[24,]),
                                 predictRisk(experimental_model,newdata = test[24,])))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
  subject.id        model risk.prediction
1         24 conventional       0.1826537
2         24 experimental       0.4429426
\end{verbatim}
\end{frame}
\begin{frame}[label={sec:orgbdb2aaa},fragile]{Evaluating model performance}
 \begin{lstlisting}[language=r,numbers=none,otherkeywords={}, deletekeywords={model,c}]
x <- Score(list("Conventional model" = conventional_model,"Experimental model" = experimental_model),
           data = test,
           formula = cvd_5year~1,
           summary = "risks",
           plots = c("roc","cal"))
summary(x,what = "score")
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
$score
Key: <Model>
                Model          AUC (%)     Brier (%)
               <fctr>           <char>        <char>
1:         Null model             <NA> 6.1 [4.9;7.4]
2: Conventional model 88.3 [84.6;92.0] 4.6 [3.7;5.5]
3: Experimental model 87.8 [84.1;91.5] 4.9 [4.0;5.8]
\end{verbatim}
\end{frame}
\begin{frame}[label={sec:orgf1b068e},fragile]{Predicted risks}
 \begin{lstlisting}[language=r,numbers=none]
plotRisk(x)
\end{lstlisting}

\begin{center}
\includegraphics[width=0.7\textwidth]{./day1-lecture2-example-predicted-risks.pdf}
\end{center}
\end{frame}
\begin{frame}[label={sec:orgeba4739},fragile]{Discrimination}
 \begin{lstlisting}[language=r,numbers=none]
plotROC(x)
\end{lstlisting}

\begin{center}
\includegraphics[width=0.7\textwidth]{./day1-lecture2-example-roc.pdf}
\end{center}
\end{frame}
\begin{frame}[label={sec:orgcb9ee49},fragile]{Calibration}
 \begin{lstlisting}[language=r,numbers=none]
plotCalibration(x)
\end{lstlisting}

\begin{center}
\includegraphics[width=0.7\textwidth]{./day1-lecture2-example-cal.pdf}
\end{center}
\end{frame}
\begin{frame}[label={sec:org4918c5e}]{Conditional versus expected performance}
Conditional prediction performance is the performance of a risk
prediction model conditional on a single-purpose dataset. 
\vfill

A researcher who provides a risk prediction model for clinical
application is naturally interested in the conditional performance of
the model.
\vfill

The conditional prediction performance can be assessed by
an external validation dataset or, with some limitations, using data
splitting.  
\end{frame}
\begin{frame}[label={sec:org39bf25c}]{Conditional versus expected performance}
Expected prediction performance is the performance
of a modeling algorithm.
It is the average performance across all the
prediction models that a modeling algorithm can produce using all
possible learning datasets of a fixed sample size.
\vfill
A researcher who
has invented a new algorithm for building prediction models is
naturally interested in the average performance.

\vfill
The expected
prediction performance can either be assessed by computer simulation
of many datasets or by using cross-validation and bootstrap methods.
\end{frame}
\begin{frame}[label={sec:org458e612}]{Uncertainty}
A probabilistic prediction has built-in uncertainty
\vfill

Paradigm: A medical risk prediction model finds people in the data set
who were alike the current person, i.e., with similar values of the
risk predictors, and summarizes what happened to them.  \vfill

Any useful model will provide more reliable predictions for people who
are well represented in the data set than people at the border of
the data set.
\end{frame}
\begin{frame}[label={sec:orga350973}]{Summary and outlook}
A medical risk prediction model predicts the probability with which an
event occurs until a fixed prediction time horizon.
\vfill

Prediction performance (metrics) can be used to decide between rival models.

\vfill

The values of the prediction performance metrics do not have a direct
clinical interpretation!

\vfill How useful a model is depends on what it is used for \dots{}
\end{frame}
\end{document}
